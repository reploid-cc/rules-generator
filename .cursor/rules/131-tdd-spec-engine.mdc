---
description: Test-driven development engine with automated test generation, complexity assessment and validation protocol
globs: 
alwaysApply: false
---
<!-- CONTENT_TARGET: AI_FACING - Mathematical notation User_Rules framework -->

# TDD.spec_engine: Test-Driven Development Framework (131)

## üéØ TDD.core_framework: Test Generation Framework

### TDD.spec_engine: Intelligent Test Generation
```
TDD.spec_engine = (
    infer_test_cases_from_œÑ()
    ‚®Å include_edge_validation_regression_cases()
    ‚®Å cross_check_against_known_issues_and_Œõ()
)

TDD.loop = (
    spec ‚Üí run ‚Üí fail ‚Üí fix ‚Üí re_run
    ‚®Å if_pass: Œ®.capture_result() ‚®Å M.sync() ‚®Å Œõ.extract()
)

TDD.spec_path = ".cursor/tasks/sprint_{n}/spec_step_{x}.md"
TDD.auto_spec_trigger = (
    generate_spec_step_x_md_if_œÑ.complexity > medium
    ‚®Å or_if_user_explicitly_requests_TDD()
)
```

### TDD.complexity_assessment: Task Complexity Evaluation
```
TDD.complexity_levels = {
    simple: (
        single_file_change ‚®Å minimal_logic ‚®Å no_dependencies
        ‚®Å estimated_effort < 1h ‚®Å no_architecture_impact
    ),
    medium: (
        multi_file_changes ‚®Å moderate_logic ‚®Å few_dependencies
        ‚®Å estimated_effort 1-4h ‚®Å component_level_impact
    ),
    complex: (
        architecture_changes ‚®Å extensive_logic ‚®Å many_dependencies
        ‚®Å estimated_effort > 4h ‚®Å system_level_impact
    )
}

TDD.trigger_conditions = (
    if_œÑ.complexity ‚â• medium
    ‚®Å or_œÑ.dependencies.count > 2
    ‚®Å or_œÑ.integration_points > 1
    ‚®Å or_user_requests_TDD()
    ‚Üí generate_TDD_spec_path()
)
```

## üéØ TDD.implementation: Testing Standards

### TDD.test_types: Required Test Categories
```
TDD.required_test_types = {
    unit: "Individual function/component testing",
    integration: "Component interaction testing",
    edge_cases: "Boundary condition testing",
    regression: "Prevent reintroduction of bugs"
}

TDD.test_structure = `
// Arrange: Set up test data and environment
const input = createTestData();
const expectedOutput = defineExpected();

// Act: Execute the function under test
const result = functionUnderTest(input);

// Assert: Verify the outcome
expect(result).toEqual(expectedOutput);
`
```

### TDD.quality_requirements: Test Quality Standards
```
TDD.quality_standards = {
    speed: "Tests complete <1s each",
    independence: "No test dependencies",
    descriptiveness: "Clear test names explain intent",
    reliability: "Consistent results across runs"
}

TDD.test_template = `
describe('ComponentName', () => {
  test('should handle valid input correctly', () => {
    // Arrange
    const input = validTestData;
    
    // Act
    const result = functionUnderTest(input);
    
    // Assert
    expect(result).toEqual(expectedOutput);
  });
  
  test('should handle edge cases gracefully', () => {
    // Test boundary conditions
    const edgeInput = createEdgeCase();
    const result = functionUnderTest(edgeInput);
    expect(result).toBeDefined();
  });
  
  test('should throw errors for invalid input', () => {
    // Test error conditions
    expect(() => {
      functionUnderTest(invalidInput);
    }).toThrow('Expected error message');
  });
});
`
```

## üéØ TDD.integration: System Integration

### TDD.task_integration: Integration with Task System
```
TDD.task_integration = (
    auto_generate_spec_if_œÑ.complexity > medium
    ‚®Å link_spec_to_T.sprint_tracking()
    ‚®Å update_T.progress_when_tests_pass()
)

TDD.quality_gates = {
    completion: "All tests must pass before step completion",
    coverage: "Test coverage requirements per Œõ.rules",
    performance: "Performance benchmarks for complex operations",
    documentation: "Documentation updated with test results"
}
```

### TDD.cross_references: Related Rules
```
TDD.related_rules = {
    "0xx-core": ["core/001-core-standards.mdc"],
    "1xx-protocols": ["protocols/111-memory-initialization.mdc"],
    "3xx-testing": ["testing/301-testing-standards.mdc"],
    "8xx-workflows": ["workflow/801-task-system.mdc"],
    "integration": ["tasks-integration.mdc"]
}
```

### TDD.system_hooks: Integration Points
```
TDD.system_hooks = {
    on_task_creation: [TDD.assess_complexity, TDD.determine_tdd_requirements],
    on_spec_generation: [TDD.create_spec_file, TDD.link_to_task],
    on_test_completion: [TDD.update_task_progress, M.sync],
    on_test_failure: [Œû.log_error_pattern, TDD.suggest_fixes]
}
```

## üéØ TDD.quality: Quality Standards

### TDD.error_protocol: Test Failure Handling
```
TDD.failure_protocol = (
    analyze_failure_determine_root_cause()
    ‚®Å fix_implementation_address_core_issue()
    ‚®Å re_run_tests_verify_fix_works()
    ‚®Å document_pattern_log_in_Œû.error_memory_if_recurring()
)
```

### TDD.metrics: Performance & Quality Metrics
```
TDD.performance_metrics = {
    execution_speed: "Monitor test runtime",
    coverage: "Track code coverage percentage",
    flakiness: "Identify unstable tests",
    resource_usage: "Memory and CPU monitoring"
}

TDD.quality_score = (
    coverage_percentage * 0.4
    ‚®Å reliability_score * 0.3  
    ‚®Å performance_score * 0.2
    ‚®Å maintainability_score * 0.1
)
```

### TDD.anti_patterns: Error Prevention
```
TDD.anti_patterns = {
    skipping_tests_for_simple_tasks: MAJOR_VIOLATION,
    incomplete_test_coverage: MAJOR_VIOLATION,
    test_after_implementation: VIOLATION,
    brittle_tests: VIOLATION,
    slow_running_tests: VIOLATION,
    missing_edge_cases: VIOLATION,
    test_dependencies: VIOLATION,
    poor_test_naming: VIOLATION
}
```

### TDD.validation_protocol: Quality Assurance
```
TDD.validation_protocol = (
    verify_test_completeness()
    ‚®Å check_coverage_meets_requirements()
    ‚®Å ensure_tests_run_efficiently()
    ‚®Å validate_test_independence()
    ‚®Å confirm_edge_cases_covered()
)
```

---
*TDD.spec_engine: comprehensive_test_driven_development_framework_with_intelligent_test_generation_complexity_assessment_quality_standards_and_system_integration*




